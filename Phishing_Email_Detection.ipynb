{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanable AI Approaches and Phishing Email Dataset**\n",
    "\n",
    "I want to work on a text base dataset probably Phishing Email Detection (kaggle.com) and use XAI methods (LIME, SHAP, ...) to explain RandomForest results and I want to try to find a way to fool the model using explanations provided by XAI and also find ways to improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing LIME\n",
    "try:\n",
    "  import lime\n",
    "except:\n",
    "  print(\"Installing LIME\")\n",
    "  !pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing modules\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phishing Email Dataset**\n",
    "\n",
    "The dataset specifies the email text body the type of emails which can be used to detect phishing emails by extensive analytics of the email text and classifying those using machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "df=pd.read_csv('Phishing_Email.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 16 null \"Email Text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove null data\n",
    "df = df.dropna(subset=['Email Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words are words like “and”, “the”, “him”, which are presumed to be uninformative in representing the content of a text, and which may be removed to avoid them being construed as signal for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as stop_words\n",
    "#Remove stop words \n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = text.split()  # Break it down into words\n",
    "    text = [word for word in text if word not in stop_words]  # Remove stop words\n",
    "    return ' '.join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_emails = df['Email Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_emails[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Email Type', data=df)\n",
    "plt.title('Email Type Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a target variable to boolean\n",
    "y = df['Email Type'].map({'Safe Email': 0, 'Phishing Email': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(cleaned_emails, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize emails using TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Vectorize emails\n",
    "X_train = vectorizer.fit_transform(x_train)\n",
    "X_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels are imbalance and we use oversampling techinque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "print(\"Number of samples before over sampling :\",X_train.shape)\n",
    "# oversample\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "print(\"Number of samples after over sampling :\",X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title AutoML experiment: Random forest\n",
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score=sklearn.metrics.f1_score(y_test, pred, average='binary')\n",
    "accuracy_score=sklearn.metrics.accuracy_score(y_test, pred)\n",
    "print(\"f1-Score of random forest\",f1_score)\n",
    "print(\"accuracy of random forest\",accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explaining predictions using LIME**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipeline = make_pipeline(vectorizer, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3\n",
    "print(cleaned_emails[i])\n",
    "print(y[i])\n",
    "print(pipeline.predict_proba([cleaned_emails[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the LIME explainer\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=['Safe Email', 'Phishing Email'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then generate an explanation with at most 10 features for an arbitrary document in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the explanation\n",
    "idx=4\n",
    "class_names = ['Safe Email', 'Phishing Email']\n",
    "exp = explainer.explain_instance(cleaned_emails[idx], pipeline.predict_proba, num_features=10)\n",
    "print('Document id: %d' % idx)\n",
    "print('Probability(Phishing Email) =', pipeline.predict_proba([cleaned_emails[idx]])[0,1])\n",
    "print('True class: %s' % class_names[y[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These weighted features are a linear model, which approximates the behaviour of the random forest classifier in the vicinity of the test example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explain as a list\n",
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explaining with a plot\n",
    "fig = exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If we remove 'save' and 'low' from the document , the prediction should move towards the opposite class (Safe Email) by about 0.2 (the sum of the weights for both features). Let's see if this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original prediction: ', pipeline.predict_proba([cleaned_emails[idx]])[0,1])\n",
    "tmp = cleaned_emails[idx]\n",
    "tmp = tmp.replace('save','')\n",
    "tmp = tmp.replace('low','')\n",
    "print(tmp)\n",
    "print('Prediction removing some features:', pipeline.predict_proba([tmp])[0,1])\n",
    "print('Difference:', pipeline.predict_proba([tmp])[0,1] - pipeline.predict_proba([cleaned_emails[idx]])[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words that affect the classifier in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing in notebook\n",
    "exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Saving explanation\n",
    "exp.save_to_file('oi.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to fool this model using provided explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3\n",
    "print(cleaned_emails[i])\n",
    "print(y[i])\n",
    "print(pipeline.predict_proba([cleaned_emails[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample is Phishing based on prediction of our mode\n",
    "and I want to add few positive word to change the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(cleaned_emails[2], pipeline.predict_proba, num_features=10)\n",
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline.predict_proba([cleaned_emails[i] + \"2000 pm thanks questions know deal cc forwarded\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could change the result just by adding 8 words at the end of text and now our email is a \"Safe Email\" !!!!!!!\n",
    "\n",
    "This is because our model used the TFIDF method to vectorize the data and does not pay attention to the position of the words in the sentence and their relationship with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Embedding**\n",
    "\n",
    "Reapeat previous steps using Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text using TensorFlow Tokenizer\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')  # oov_token for out-of-vocabulary words\n",
    "tokenizer.fit_on_texts(cleaned_emails)  # Fit tokenizer to the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text to sequences of tokens (integers)\n",
    "sequences = tokenizer.texts_to_sequences(cleaned_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to ensure uniform length\n",
    "padded_sequences = pad_sequences(sequences, padding='post', maxlen=100)  # Pad up to a max length of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the embedding model\n",
    "embedding_dim = 100  # Size of the embedding vector\n",
    "\n",
    "# Define the embedding layer in TensorFlow\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=10000, output_dim=embedding_dim, input_length=100)\n",
    "\n",
    "# Pass the padded sequences through the embedding layer\n",
    "embeddings = embedding_layer(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the embedding output (for example purposes, showing embeddings of first text)\n",
    "print(f\"Embedding shape: {embeddings.shape}\")  # (batch_size, sequence_length, embedding_dim)\n",
    "print(embeddings[0].numpy())  # Embeddings for the first text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embeddings to numpy and average them to create a single vector for each text\n",
    "# The output `embeddings` shape is (num_samples, sequence_length, embedding_dim)\n",
    "# We take the mean across the sequence length to get a fixed-size vector for each sample\n",
    "averaged_embeddings = tf.reduce_mean(embeddings, axis=1).numpy()  # Shape: (num_samples, embedding_dim)\n",
    "averaged_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "emb_X_train, emb_X_test, emb_y_train, emb_y_test = train_test_split(averaged_embeddings, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "print(\"Number of samples before over sampling :\",emb_X_train.shape)\n",
    "# oversample\n",
    "emb_X_train, emb_y_train = oversample.fit_resample(emb_X_train, emb_y_train)\n",
    "print(\"Number of samples after over sampling :\",emb_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier\n",
    "emb_rf = sklearn.ensemble.RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "emb_rf.fit(emb_X_train, emb_y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "emb_y_pred = emb_rf.predict(emb_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score=sklearn.metrics.f1_score(emb_y_test, emb_y_pred, average='binary')\n",
    "accuracy_score=sklearn.metrics.accuracy_score(emb_y_test, emb_y_pred)\n",
    "print(\"f1-Score of random forest\",f1_score)\n",
    "print(\"accuracy of random forest\",accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the LIME explainer\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=['Safe Email', 'Phishing Email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_pred(data):\n",
    "    # Convert the text to sequences of tokens (integers)\n",
    "    sequences = tokenizer.texts_to_sequences(data)\n",
    "    # Pad the sequences to ensure uniform length\n",
    "    padded_sequences = pad_sequences(sequences, padding='post', maxlen=100)  # Pad up to a max length of 100\n",
    "    # Pass the padded sequences through the embedding layer\n",
    "    embeddings = embedding_layer(padded_sequences)\n",
    "    averaged_embeddings = tf.reduce_mean(embeddings, axis=1).numpy()  # Shape: (num_samples, embedding_dim)\n",
    "    y_pred = emb_rf.predict_proba(averaged_embeddings)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the explanation\n",
    "idx=4\n",
    "class_names = ['Safe Email', 'Phishing Email']\n",
    "exp = explainer.explain_instance(cleaned_emails[idx], emb_pred, num_features=10)\n",
    "print('Document id: %d' % idx)\n",
    "print('Probability(Phishing Email) =', emb_pred([cleaned_emails[idx]])[0,1])\n",
    "print('True class: %s' % class_names[y[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing in notebook\n",
    "exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3\n",
    "print(cleaned_emails[i])\n",
    "print(y[i])\n",
    "print(emb_pred([cleaned_emails[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emb_pred([cleaned_emails[i] + \"2000 pm thanks questions know deal cc forwarded\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of Word embedding could not improve our model, it seems that it is better to use other models such as RNN, LSTM, etc. to improve the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use LSTM**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Disable all GPU devices\n",
    "tf.config.set_visible_devices([], 'GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "\n",
    "# Load your CSV file into a DataFrame\n",
    "data = pd.read_csv('Phishing_Email.csv')  # Replace with the actual path to your CSV\n",
    "\n",
    "#Remove null data\n",
    "data = data.dropna(subset=['Email Text'])# Separate the features (text) and labels\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as stop_words\n",
    "#Remove stop words \n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = text.split()  # Break it down into words\n",
    "    text = [word for word in text if word not in stop_words]  # Remove stop words\n",
    "    return ' '.join(text)\n",
    "\n",
    "\n",
    "texts = data['Email Text'].apply(clean_text).values  # Text data\n",
    "labels = data['Email Type'].map({'Safe Email': 0, 'Phishing Email': 1}).values  # Labels (0 or 1 for binary classification)\n",
    "\n",
    "# Parameters\n",
    "max_features = 10000  # Maximum number of words to keep in the tokenizer\n",
    "maxlen = 100  # Maximum length of sequences (texts will be padded or truncated)\n",
    "embedding_dim = 128  # Dimension of the word embedding\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# Pad the sequences to ensure they are of the same length\n",
    "X = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=maxlen))\n",
    "model.add(LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification, so sigmoid output\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print(f\"Test score: {score}\")\n",
    "print(f\"Test accuracy: {acc}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "predictions = (predictions > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the LIME explainer\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=['Safe Email', 'Phishing Email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def lstm_pred(texts):\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    X = pad_sequences(sequences, maxlen=maxlen)\n",
    "    arr = np.array([1-model.predict(X),model.predict(X)])\n",
    "    return np.hstack([arr[0], arr[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the explanation\n",
    "idx=4\n",
    "class_names = ['Safe Email', 'Phishing Email']\n",
    "exp = explainer.explain_instance(cleaned_emails[idx], lstm_pred, num_features=10)\n",
    "print('Document id: %d' % idx)\n",
    "print('Probability(Phishing Email) =', lstm_pred([cleaned_emails[idx]])[0,1])\n",
    "print('True class: %s' % class_names[y[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3\n",
    "print(cleaned_emails[i])\n",
    "print(y[i])\n",
    "print(lstm_pred([cleaned_emails[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lstm_pred([cleaned_emails[i] + \"2000 pm thanks questions know deal cc forwarded\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
